# AIML Questions and Answers (Group 18)

## Description
Answer the given AIML Questions: Modeling a domain-specific GPT-variant model that can answer the questions specific to the AIML course. It has been observed that while pretrained models can produce relevant textual output for general, open-domain textual prompts, the models lack the capability of producing finer outputs when it comes to domain-specific tasks. For this purpose, we commonly finetune the model on a dataset specific to that task, to tailor its expertise on it. Here, the participants will work together to build a novel, relevant dataset for the task. Post finetuning, they will observe its performance on unseen, related questions. \
**Project Proposal**: [Group 18 - Capstone Project proposal - Google Docs.pdf](https://github.com/anukvma/group18_email_subject_generation/blob/main/Group%2018%20-%20Capstone%20Project%20proposal%20-%20Google%20Docs.pdf)

## DataSet
Dataset used is from the below repository for fine tuning the models
[https://drive.google.com/drive/folders/1O2qMvEfKXyhdF1HcHIck6eWLPRMGmPUv?usp=sharing](https://drive.google.com/drive/folders/1O2qMvEfKXyhdF1HcHIck6eWLPRMGmPUv?usp=sharing)

## Models
The following models are fine tuned 
| LLM     	| Framework             | Model Type        | Training Steps       	| Evaluation Method    	| 
|---------	|---------------------	|-------------------|---------------------	|----------------------	|
| Bart    	| Transformer           | Base model       	| 600                  	| ROUGE Score          	|

## Training Details

### Bart
**Code File**: [Group18FineTuneBartEmailSubjectFinal.ipynb](https://github.com/anukvma/group18_email_subject_generation/blob/main/Group18FineTuneBartEmailSubjectFinal.ipynb) \
Model: facebook/bart-large-xsum \
Training Framework: Transformer Seq2SeqTrainer \
Training Arguments: 
```
Seq2SeqTrainingArguments(
    model_dir,
    evaluation_strategy="steps",
    eval_steps=100,
    logging_strategy="steps",
    logging_steps=100,
    save_strategy="steps",
    save_steps=100,
    learning_rate=4e-5,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=6,
    predict_with_generate=True,
    fp16=True,
    load_best_model_at_end=True,
    metric_for_best_model="rouge1",
    report_to="tensorboard"
)
**Result**:
Training:
Step	Training Loss	Validation Loss	Rouge1	Rouge2	Rougel	Rougelsum	Gen Len
100	3.014600	2.570830	33.137500	14.415600	27.374400	28.190300	31.850000
200	2.087700	2.501255	35.015200	15.145300	28.741700	29.822700	34.110000
300	1.507400	2.540349	35.207000	14.807500	28.700600	30.715900	41.570000
400	1.089400	2.717226	34.006500	14.434000	27.868000	29.710000	41.610000
500	0.776600	2.945216	36.228900	16.209900	29.720400	31.375800	40.040000
600	0.577400	3.062018	35.786700	16.206200	29.868600	31.719700	41.520000

Test:

```
## Inference Results

### Email Body:
﻿Please help summarize the provided email body and generate email subject Kevin Presto is requesting that you attend a meeting regarding Organizing an Action Plan for the Start-up of Netco.\nThe meeting will be held in ECS 06716 at 9:30 am, Wednesday, January 2, 2002.\nFor Tim and Chris, could you please call 713-584-2067.\nThis is the telephone number in the conference room.\nIf you should have any questions, please call T Jae Black at 3-5800.\nThanks
 
### Reference Output:
meeting regarding the netco start up action plan

### Llama3 Model Output:
﻿Netco Action Plan Meeting

### Mistral Model Output:
﻿Meeting on Netco Startup

### T5 Model Output:
Organizing an Action Plan for the Start

### Bart Model Output:
Organizing an Action Plan


## Model Evaluation Criteria
### Rouge Score
Rouge score measures the similarity between the generated subject and the provided subject using overlapping n-grams. It ranges from 0 to 1, with higher values indicating better summary quality.
## Result
| LLM     	| Rogue1              	| Rogue2               	| RougeL              	| RogueLSum            	|
|---------	|---------------------	|----------------------	|---------------------	|----------------------	|
| Mistral 	| 0.04175057546404236 	| 0.015307029349338995 	| 0.03865576026979294 	| 0.040112317820734385 	|
| Llama3  	| 0.044540652323630435 	| 0.016282087086038018 	| 0.03984053234184394  	| 0.04157418257161926  	|
| T5      	| 0.144567            	| 0.070306             	| 0.140258            	| 0.141119             	|
| Bart    	| 0.267373            	| 0.134597             	| 0.249993            	| 0.250012             	|

## Observations
1. Generative models are very large to be trained on base model, we had to use quantized versions. Also for training we used [PEFT](https://huggingface.co/docs/peft/en/package_reference/lora) 
2. Email subjects generated by both Generative and Seq2Seq Model is contextually correct.
3. Generative models generate word's synonyms, hence Rogue score is very low.
4. Seq2Seq models pick up the words from Email content, which is expected in this experiment, hence Rouge score is high.
5. Bart and T5 both models are encoder-decoder type models, but Bart performs better than T5 due to:
   * Type of corpus these models are trained with is different
   * T5 randomly drop 15% tokens during training, but Bart is trained by corrupting documents and then optimizing a reconstruction loss
   * T5 uses relative positional encoding, where Bart uses absolute positional encoding
   * Bart initializes parameters from N (0, 0.02), where T5 N(0, 1/sqrt(d_model))
     
## HuggingFace Demo URL
**Gradio App:** https://huggingface.co/spaces/GSridhar1982/EmailSubjectGenerationDemo \
Code Files: \
[GradioAppWithModelSelection.ipynb](https://github.com/anukvma/group18_email_subject_generation/blob/main/GradioAppWithModelSelection.ipynb): Gradio App Notebook with model selection option. \
[Group18EmailSubjectGradioApp.ipynb](https://github.com/anukvma/group18_email_subject_generation/blob/main/Group18EmailSubjectGradioApp.ipynb): Gradio App without model selection \

**FAST API:** https://anukvma-emailsubjectapi.hf.space \
Code files: [api(folder)](https://github.com/anukvma/group18_email_subject_generation/tree/main/api): Code for Fast API includes Dockerfile, requirements.txt and main.py \
Curl command for API call:
```
curl --location --request GET 'https://anukvma-emailsubjectapi.hf.space' \
--header 'Content-Type: application/json' \
--data-raw '{
    "model_name":"anukvma/bart-base-medium-email-subject-generation-v5",
    "email_content": "Harry - I got kicked out of the system, so I'\''m sending this from Tom'\''s account. He can fill you in on the potential deal with STEAG. I left my resume on your chair. I'\''ll e-mail a copy when I have my home account running. My contact info is:"
}'
```
