Question,Answer
"What is a linear classifier?","A linear classifier is a model that makes predictions based on a linear combination of input features. It decides the class by checking on which side of a decision boundary (a hyperplane) a data point lies."
"How does a linear classifier make predictions?","A linear classifier predicts by calculating the dot product of input features with weights and adding a bias term. The sign of the output determines the class."
"What is the objective function in a linear classifier?","The objective function often used is the loss function, such as hinge loss in SVMs or cross-entropy in logistic regression, which measures the error between predicted and actual labels."
"What is gradient descent?","Gradient descent is an optimization algorithm that iteratively updates model parameters to minimize a loss function. It moves in the direction of the negative gradient of the loss function."
"How does learning rate affect gradient descent?","The learning rate controls the step size in gradient descent. A small learning rate leads to slow convergence, while a large learning rate may overshoot the minimum, causing instability."
"What is the role of the bias term in a linear classifier?","The bias term allows the decision boundary to shift away from the origin, enabling the model to better fit the data, especially when the data is not centered around the origin."
"What is the difference between batch gradient descent and stochastic gradient descent (SGD)?","Batch gradient descent updates weights after computing the gradient over the entire dataset, while SGD updates weights after each individual training example, making it faster but noisier."
"What is the significance of the decision boundary in a linear classifier?","The decision boundary separates the input space into regions corresponding to different class labels. Itâ€™s defined by the weights and bias in the model."
"Why might gradient descent converge to a local minimum instead of a global minimum?","Gradient descent may converge to a local minimum in non-convex functions, where multiple minima exist. However, for convex functions like those in linear classifiers, it converges to a global minimum."
"How can overfitting be reduced in linear classifiers?","Overfitting can be reduced using regularization techniques (like L1 or L2), which penalize large weights, or by using techniques like cross-validation, early stopping, or adding more training data."
"What is the purpose of a loss function in machine learning?","The loss function measures the difference between the predicted values and the actual values. It quantifies how well the model is performing, guiding the optimization process to minimize errors."
"What is the difference between mean squared error (MSE) and cross-entropy loss?","MSE is used in regression tasks and measures the average squared difference between predicted and actual values. Cross-entropy loss is used in classification tasks and measures the difference between predicted probabilities and the actual class labels."
"How does regularization affect the loss function?","Regularization adds a penalty term to the loss function to discourage large model weights, preventing overfitting. Common regularization techniques include L1 (lasso) and L2 (ridge) regularization, which penalize the absolute sum and the square of weights, respectively."
"What is K-Nearest Neighbors (KNN)?","K-Nearest Neighbors (KNN) is a simple, non-parametric algorithm used for classification and regression. It classifies a data point based on how its neighbors are classified."
"How does KNN determine the class of a new data point?","KNN assigns a class to a new data point based on the majority class among its k-nearest neighbors in the feature space."
"How is distance measured in KNN?","Distance in KNN is typically measured using Euclidean distance, but other metrics like Manhattan or Minkowski distance can also be used depending on the problem."
"How does KNN handle multi-class classification?","KNN handles multi-class classification by assigning the class that is most common among the k-nearest neighbors, irrespective of the number of classes."
"How does KNN perform feature scaling, and why is it important?","Feature scaling is important in KNN because it relies on distance metrics. Without scaling, features with larger ranges can dominate the distance calculation, skewing the results."
"What are some methods to improve KNN efficiency?","Efficiency in KNN can be improved by using techniques like KD-Trees, Ball Trees, or approximate nearest neighbors to reduce the number of distance calculations."
"What is linear regression?","Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data."
"What is the equation of a simple linear regression model?","The equation of a simple linear regression model is y = mx + b, where y is the dependent variable, x is the independent variable, m is the slope, and b is the intercept."
"How is the goodness of fit measured in linear regression?","The goodness of fit in linear regression is commonly measured using the R-squared value, which indicates the proportion of variance in the dependent variable explained by the independent variables."
"What is the purpose of the intercept term in linear regression?","The intercept term in linear regression represents the expected value of the dependent variable when all independent variables are zero. It shifts the regression line up or down."
"What assumptions are made in linear regression?","Linear regression assumes linearity, independence of errors, homoscedasticity (constant variance of errors), and normality of residuals."
"What is logistic regression?","Logistic regression is a statistical method used for binary classification problems. It models the probability that a given input belongs to a particular class using a logistic function."
"What is the equation of a logistic regression model?","The logistic regression model is represented by log(odds) = b0 + b1x1 + ... + bnxn, where odds = p/(1-p) and p is the probability of the positive class."
"What is the role of the sigmoid function in logistic regression?","The sigmoid function in logistic regression maps the output of the linear combination of inputs to a probability value between 0 and 1."
"How is the loss function defined in logistic regression?","The loss function in logistic regression is the cross-entropy loss (or log-loss), which measures the difference between predicted probabilities and actual binary labels."
"What is the difference between linear regression and logistic regression?","Linear regression is used for predicting continuous outcomes, while logistic regression is used for binary classification. Linear regression uses a linear function, while logistic regression uses a logistic function."
"What is a decision tree?","A decision tree is a supervised learning algorithm used for classification and regression. It splits the data into subsets based on the most significant attribute, creating a tree-like model of decisions."
"How does a decision tree determine the best split?","A decision tree determines the best split by evaluating criteria like Gini impurity, information gain, or mean squared error, depending on the problem type (classification or regression)."
"What is overfitting in decision trees, and how can it be prevented?","Overfitting occurs when a decision tree becomes too complex, capturing noise in the data. It can be prevented by pruning the tree, setting a maximum depth, or requiring a minimum number of samples per leaf."
"What are the advantages of using decision trees?","Advantages of decision trees include their interpretability, ability to handle both numerical and categorical data, and no need for feature scaling or normalization."
"What is pruning in the context of decision trees?","Pruning is the process of removing branches from a decision tree that provide little predictive power, reducing complexity and helping to prevent overfitting."
"What is a Support Vector Machine (SVM)?","SVM is a supervised learning algorithm used for classification and regression. It finds the hyperplane that best separates the data into different classes with the maximum margin."
"What is a hyperplane in the context of SVM?","A hyperplane is a decision boundary that separates different classes in the feature space. SVM aims to find the hyperplane with the maximum margin between classes."
"What is the margin in SVM, and why is it important?","The margin is the distance between the hyperplane and the nearest data points (support vectors) from either class. A larger margin generally leads to better generalization."
"What are support vectors in SVM?","Support vectors are the data points closest to the hyperplane. They are critical in defining the position and orientation of the hyperplane."
"What is the kernel trick in SVM?","The kernel trick allows SVM to operate in a high-dimensional space by transforming the input data into a higher dimension, making it possible to find a linear separator for non-linear data."
"What are some common types of kernels used in SVM?","Common kernels include the linear kernel, polynomial kernel, radial basis function (RBF) kernel, and sigmoid kernel. The choice of kernel depends on the nature of the data."
"What is the role of the regularization parameter (C) in SVM?","The regularization parameter (C) controls the trade-off between maximizing the margin and minimizing classification error. A smaller C creates a wider margin but allows more misclassifications."
"What is the difference between a hard margin and a soft margin in SVM?","A hard margin SVM does not allow any misclassification and requires a perfectly separable dataset. A soft margin SVM allows some misclassification to improve generalization."
"What is ensemble learning?","Ensemble learning is a technique that combines multiple models (learners) to improve overall performance. It leverages the strengths of individual models to create a more robust predictor."
"What are the common types of ensemble methods?","Common ensemble methods include Bagging (e.g., Random Forest), Boosting (e.g., AdaBoost, Gradient Boosting), and Stacking, each with different approaches to combining models."
"What is Bagging in ensemble methods?","Bagging, or Bootstrap Aggregating, involves training multiple models on different random subsets of the data and averaging their predictions to reduce variance and avoid overfitting."
"What is Boosting in ensemble methods?","Boosting is an iterative technique where models are trained sequentially, with each new model focusing on correcting errors made by previous models, thereby reducing bias and variance."
"What is Random Forest, and how does it work?","Random Forest is an ensemble method that uses multiple decision trees trained on different data subsets. It combines their predictions by averaging (for regression) or majority voting (for classification)."
"What is the role of feature importance in Random Forest?","Feature importance in Random Forest quantifies the contribution of each feature to the model's decision-making process, helping in feature selection and understanding the model."
"What is the difference between Bagging and Boosting?","Bagging reduces variance by averaging multiple independent models, while Boosting reduces bias by sequentially improving weak learners. Bagging is parallel; Boosting is sequential."
"What is NumPy and what is it used for?","NumPy is a fundamental Python library for numerical computing. It provides support for arrays, matrices, and a collection of mathematical functions to operate on these data structures."
"How do you create a NumPy array?","A NumPy array can be created using the np.array() function by passing a list or list of lists, e.g., np.array([1, 2, 3])."
"What is pandas and what are its main data structures?","Pandas is a Python library used for data manipulation and analysis. Its main data structures are Series (1D) and DataFrame (2D), which allow for easy handling of labeled data."
"How do you select a column from a pandas DataFrame?","A column from a pandas DataFrame can be selected using either df['column_name'] or df.column_name, where df is the DataFrame."
"What is scikit-learn (sklearn) used for?","Scikit-learn (sklearn) is a Python library used for machine learning. It provides tools for classification, regression, clustering, dimensionality reduction, and model selection."
"How do you split data into training and testing sets using scikit-learn?","Data can be split using sklearn's train_test_split() function, e.g., X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)."
"What is SciPy and how does it relate to NumPy?","SciPy is a Python library built on top of NumPy, providing additional functionality for scientific computing, including optimization, integration, interpolation, and statistical functions."
"How do you compute the mean of a NumPy array?","The mean of a NumPy array can be computed using np.mean(array), where array is the NumPy array."
"How do you handle missing data in a pandas DataFrame?","Missing data in a pandas DataFrame can be handled using methods like df.dropna() to remove missing values or df.fillna(value) to fill them with a specified value."
"What is the role of the fit() method in scikit-learn?","The fit() method in scikit-learn is used to train a model on the provided dataset by learning the relationship between input features and the target variable."