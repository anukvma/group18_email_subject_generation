File name,Topic,Question,Answer
L1-Beyond-AlexNet_V1.8-CNN,"CNN, Alex-Net",What are the primary improvements that VGGNet introduced over AlexNet?,"VGGNet introduced several improvements over AlexNet, including the use of smaller receptive fields throughout the network, such as 3x3 convolutional layers instead of the larger 5x5 used in AlexNet. This design choice allowed for increased non-linearity and reduced the number of parameters, making the network deeper and more efficient."
L1-Beyond-AlexNet_V1.8-CNN,"CNN, Alex-Net",How does GoogLeNet reduce the number of operations compared to traditional convolutional layers?,"GoogLeNet introduces the concept of a 1x1 convolutional layer, which acts as a bottleneck layer. This layer significantly reduces the number of operations required by first reducing the depth (number of channels) before applying larger convolutional filters, leading to a reduction from 120 million to 12.4 million operations in the example provided."
L1-Beyond-AlexNet_V1.8-CNN,"CNN, Alex-Net","What is the vanishing gradient problem, and how do ResNets address it?","The vanishing gradient problem occurs when gradients diminish as they are propagated backward through deep networks, making it difficult to train the earlier layers. ResNets address this issue by introducing skip connections, which allow gradients to flow directly through the network, thereby preventing them from vanishing and enabling the training of much deeper networks."
L1-Beyond-AlexNet_V1.8-CNN,"CNN, Alex-Net",What are the key factors to consider when choosing a CNN architecture for production?,"When choosing a CNN architecture for production, key factors include accuracy, model complexity, memory usage, computational complexity, and inference time. It's important to balance these factors according to specific production constraints and the desired performance metrics."
L1-Beyond-AlexNet_V1.8-CNN,"CNN, Alex-Net",What is the relationship between model complexity and memory usage in CNNs?,"There is generally a linear relationship between model complexity and memory usage in CNNs. As the complexity of the model increases, so does the amount of memory it requires, making it crucial to consider this trade-off when designing or selecting a network for a specific application."
L2-Beyond-BackProp_V1.8,Backptopagation,What are the challenges in finding the global minima during training of deep neural networks?,"The challenges in finding the global minima include encountering saddle points, where the gradient is a local minima in one direction and a local maxima in another, cliffs where the gradient is too high, and plateaus where the gradient is almost zero. Additionally, the vanishing gradient problem and exploding gradients can make it difficult to find the global minima."
L2-Beyond-BackProp_V1.8,Backptopagation,How does Gradient Descent with Momentum improve the optimization process in neural networks?,"Gradient Descent with Momentum improves the optimization process by accumulating momentum from previous gradients, which helps the optimizer to continue moving in the same direction even if the gradient is small. This helps the model to escape local minima and reach the global minima more efficiently by preventing the optimizer from getting stuck in shallow minima or saddle points."
L2-Beyond-BackProp_V1.8,Backptopagation,What is the purpose of learning rate scheduling in training neural networks?,"Learning rate scheduling is used to adjust the learning rate during training, typically by reducing it according to a predefined schedule. This helps in stabilizing the training process and allows the model to converge more effectively. Common learning rate schedules include step decay, exponential decay, cosine decay, and reducing the learning rate when the performance plateaus."
L2-Beyond-BackProp_V1.8,Backptopagation,What is the concept of Dropout as a regularization technique in neural networks?,"Dropout is a regularization technique where during each training iteration, individual neurons are randomly ""dropped out"" with a certain probability, meaning their contribution is ignored in both the forward and backward passes. This forces the network to learn more robust features, as it cannot rely on any particular neuron being present, which helps in preventing overfitting."
L2-Beyond-BackProp_V1.8,Backptopagation,How does weight initialization affect the training of deep neural networks?,"Proper weight initialization is crucial as it impacts the convergence of the training process. Poor initialization, such as setting all weights to zero, can lead to neurons learning the same features and hinder the learning process. Common strategies include random initialization using Gaussian distribution, Xavier initialization, and Kaiming initialization, which help in setting the initial weights such that they facilitate effective gradient flow during training."
PEFT-LoRa,PEFT-LoRa,How much GPU RAM is required to store a model with 1 billion parameters using 32-bit precision?,Storing a model with 1 billion parameters using 32-bit precision requires 4GB of GPU RAM. 
PEFT-LoRa,PEFT-LoRa,"What is the GPU RAM requirement for GPT-3, which has 175 billion parameters?  ",GPT-3 requires 700GB of GPU RAM just to store the model. 
PEFT-LoRa,PEFT-LoRa,What happens to storage requirements when converting to 16-bit (FP16) precision? ,"Converting to 16-bit (FP16) precision halves the storage requirements, reducing it to 2 bytes per parameter. "
PEFT-LoRa,PEFT-LoRa,What additional storage is needed when training a model beyond just the model parameters?   ,"Additional storage is needed to store optimizer states, gradients, activations, and temporary variables. "
PEFT-LoRa,PEFT-LoRa,What is Low-rank Adaptation (LoRA) in the context of model fine-tuning?   ,"Low-rank Adaptation (LoRA) involves decomposing the weight matrix into a product of two smaller matrices, typically aiming to reduce the rank of the attention weight matrices. "
PEFT-LoRa,PEFT-LoRa,What are the limitations of Parameter-Efficient Fine-Tuning (PEFT)? ,"PEFT struggles to match the performance of full fine-tuning, doesn’t make inference more efficient, doesn’t reduce the cost of storing large models, and requires full forward and backward passes. "
PEFT-LoRa,PEFT-LoRa,What is the purpose of scaling factor (??) in LoRA?,The scaling factor (??) is used to scale the low-rank matrices during the adaptation process in LoRA. 
PEFT-LoRa,PEFT-LoRa,What are the two matrices used in LoRA for weight matrix decomposition?  ,The two matrices used in LoRA are matrix ?? (?? ? ????×??) and matrix ?? (?? ? ????×??). 
PEFT-LoRa,PEFT-LoRa,What is an example of a task that a decoder-based language model would perform?  ,"An example is predicting the next token in a sequence based on previous tokens, such as predicting “dog” in the sequence “the quick brown fox jumps over the lazy ________”. "
PEFT-LoRa,PEFT-LoRa,What is a significant challenge mentioned in the document when using pure 16-bit floating-point neural networks?  ,"A challenge is the need for additional storage for optimizer states, gradients, and other variables during training, despite the reduced model storage from 16-bit precision. "
LangChain_RAG,LangChain & RAG,"What is RAG, and how does it work?","RAG (Retrieval-Augmented Generation) is a framework that retrieves relevant information from a knowledge base and then generates a response by combining this retrieved information with a prompt. It typically involves three steps: retrieval, augmentation, and generation?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,What is the purpose of LangChain?,"LangChain is an open-source framework designed for developing applications powered by Large Language Models (LLMs). It focuses on creating complex projects by composing modular components like document loaders, chains, agents, and more?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,What are the main components of LangChain?,"The main components of LangChain include models (LLMs, Chat Models, Text Embedding Models), prompts (Prompt Template, Output Parsers), chains (sequential or complex chains), agents (for tool interaction), and indexes (document loaders, text splitters, vector stores)?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,How does LangChain handle document loading?,"LangChain uses document loaders to load documents into its own Document object. These loaders might require additional libraries (e.g., pypdf for PDF loading). LangChain also supports integrations with third-party sources like Google Cloud and Wikipedia?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,What is a Prompt Template in LangChain?,A Prompt Template in LangChain is an abstraction that allows the reuse of well-structured prompts in sophisticated applications. It helps in managing and organizing prompts that might be long or detailed?(LangChain_RAG).
LangChain_RAG,LangChain & RAG,What is the role of agents in LangChain?,"Agents in LangChain are powerful components that use models, data connections, chains, and memory to perform tasks. They can interact with external tools, APIs, and data stores to reason through requests and take actions based on observational outputs?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,What is the Maximum Marginal Relevance (MMR) algorithm?,The Maximum Marginal Relevance (MMR) algorithm is used to choose the most relevant and diverse responses from a set of retrieved chunks. It helps in selecting the best information to augment the query?(LangChain_RAG).
LangChain_RAG,LangChain & RAG,What are some challenges LLMs face according to the document?,"LLMs face challenges like not being up-to-date, lacking domain-specific knowledge, and struggling with real-time information. They also have limitations in handling complex calculations and may produce hallucinations or plausible but incorrect information?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,How does LangChain address the limitations of LLMs?,"LangChain addresses LLM limitations by integrating them with other tools, allowing them to access real-time data, specialized knowledge, and perform specific tasks through the use of agents and external tools?(LangChain_RAG)."
LangChain_RAG,LangChain & RAG,What is the significance of iterative prompt development?,Iterative prompt development involves refining prompts based on analysis of the results. It is crucial for improving the accuracy and relevance of the outputs by making the model spend more computational effort on complex tasks
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What is the main drawback of one-hot encoding in representing word meanings in neural networks?,"One-hot encoding results in a large and sparse embedding matrix with dimensions equal to the vocabulary size, which cannot effectively capture word meanings."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,"What is Word2Vec, and on what data was Google's pre-trained Word2Vec model trained?","Word2Vec is a model that provides 300-dimensional word vectors, and Google's pre-trained Word2Vec model was trained on approximately 100 billion words from a Google News dataset."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,How does Byte Pair Encoding (BPE) handle rare words in the GPT-2 model?,"In GPT-2, rare words are decomposed into meaningful subwords using BPE, which helps the model to understand them better."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What problem does SentencePiece address in subword tokenization methods?,SentencePiece addresses the problem of languages that do not use spaces to separate words by including the space character in the set of tokens used for building vocabularies.
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What is a key feature of the Transformer architecture introduced by Vaswani et al.?,"A key feature of the Transformer architecture is the use of self-attention and multi-head attention mechanisms, without any recurrent connections."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What is the primary difference between the OpenAI GPT and BERT models?,"The primary difference is that GPT uses a left-to-right Transformer, whereas BERT uses a bidirectional Transformer that is jointly conditioned on both left and right contexts."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What is the purpose of the multi-head self-attention mechanism in Transformers?,"The multi-head self-attention mechanism allows the model to focus on different parts of the input sentence when processing each word, improving the model's ability to capture complex relationships."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What task is primarily used during the pretraining of GPT models?,"The primary task used during the pretraining of GPT models is language modeling, where the model is trained to predict the next word in a sequence."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,What limitation is associated with GPT-3 regarding its model structure?,"A limitation of GPT-3 is that it is not bidirectional, which means it processes text in a unidirectional manner, potentially missing out on context that could be gleaned from both directions."
25May2024-Pretrained-Transformer-based-models.pptx,Pretrained Transformer based models,How does BERT’s architecture differ in terms of pre-training tasks compared to GPT?,"BERT’s architecture is pre-trained using two tasks: Masked Language Modeling (MLM) and Next Sentence Prediction (NSP), while GPT focuses solely on the task of next word prediction."
L3-Self-Supervised-Learning,Self Supervised Learning,What is self-supervised learning (SSL)?,"Self-Supervised Learning (SSL) is a type of representation learning where a model is trained on unlabelled data by creating supervised learning tasks. This approach helps in learning good data representations that can be transferred to various downstream tasks, especially when labeled data is scarce."
L3-Self-Supervised-Learning,Self Supervised Learning,Why is self-supervised learning important?,"SSL is important because it addresses the issue of the scarcity of labeled data, which is expensive to obtain. By leveraging large amounts of unlabeled data, SSL can learn useful representations that can improve performance on tasks with limited labeled examples and enable zero-shot transfer to new tasks."
L3-Self-Supervised-Learning,Self Supervised Learning,What are the two popular methods for framing self-supervised learning tasks?,The two popular methods are: 1) Self-prediction: Predicting a part of a data sample using another part of the same sample. 2) Contrastive learning: Predicting the relationship among multiple data samples.
L3-Self-Supervised-Learning,Self Supervised Learning,What is contrastive learning?,"Contrastive learning is a method in SSL where the model learns to distinguish between similar (positive) and dissimilar (negative) data samples. The goal is to create an embedding space where similar samples are close to each other, while dissimilar samples are far apart."
L3-Self-Supervised-Learning,Self Supervised Learning,What is a pretext task in the context of self-supervised learning?,"A pretext task is an artificially created task that does not require manual labeling but is designed to train a model to learn useful features. Examples include predicting the rotation of an image, solving jigsaw puzzles, or filling in missing pixels in an image."
L3-Self-Supervised-Learning,Self Supervised Learning,Can you give an example of a pretext task used in NLP?,"In NLP, a common pretext task is predicting the center word given a window of surrounding words, as seen in models like Word2Vec. Another example is predicting masked words in a sentence, which is used in models like BERT."
L3-Self-Supervised-Learning,Self Supervised Learning,How does contrastive loss function in self-supervised learning?,"The contrastive loss function works by encoding data into embedding vectors, ensuring that samples from the same class (positives) have similar embeddings, while samples from different classes (negatives) have different embeddings. This helps the model to learn meaningful representations."
L3-Self-Supervised-Learning,Self Supervised Learning,"What is the purpose of the ""jigsaw puzzle"" pretext task?","The ""jigsaw puzzle"" pretext task involves shuffling patches of an image and having the model predict the correct arrangement. This task helps the model learn spatial relationships and visual structures within an image."
L3-Self-Supervised-Learning,Self Supervised Learning,"What is the significance of the statement ""Self-supervised learning is supervised learning without specific task annotations""?","This statement highlights that SSL creates supervised tasks from unlabeled data, effectively simulating the conditions of supervised learning but without the need for labeled data. This allows models to learn from vast amounts of unlabeled data, which is more readily available."
L3-Self-Supervised-Learning,Self Supervised Learning,How is self-supervised learning applied in vision and NLP?,"In vision, SSL is applied through tasks like predicting rotations, solving jigsaw puzzles, and inpainting. In NLP, it is applied through tasks like predicting masked words, sentence ordering, and context prediction. These tasks help in learning representations that can be used in downstream applications like image classification and language understanding."
B21_ComputerVision,Computer Vision,What is the primary goal of computer vision?,"The primary goal of computer vision is to extract all possible information about a visual scene through computer processing, including answering questions like What? When? Where? Who? How? Why? and How many?"
B21_ComputerVision,Computer Vision,Why is computer vision considered difficult?,"Computer vision is considered difficult because it involves understanding and interpreting visual data, which includes handling large intra-class variations, recognizing objects despite changes in appearance, and replicating the sophisticated but not fully understood mechanisms of human vision."
B21_ComputerVision,Computer Vision,"What are the three ""R's"" of computer vision mentioned in the document?","The three ""R's"" of computer vision are Reorganization (segmentation), Recognition (connecting visual input to memory), and Reconstruction (measuring and recreating 3D models of what we see)."
B21_ComputerVision,Computer Vision,What is the role of segmentation in computer vision?,"Segmentation in computer vision involves grouping similar parts of an image into meaningful regions, which is crucial for recognizing and reconstructing objects within a visual scene."
B21_ComputerVision,Computer Vision,How does the pinhole camera model relate to computer vision?,"The pinhole camera model is a mathematical representation used in computer vision to understand how a camera projects a 3D scene onto a 2D image, which helps in tasks like recovering world geometry and calibrating cameras."
B21_ComputerVision,Computer Vision,What are some of the applications of planar homography in computer vision?,"Planar homography in computer vision is used for applications like removing perspective distortion, rendering planar textures, rendering planar shadows, and estimating camera pose for augmented reality."
B21_ComputerVision,Computer Vision,Why is the concept of stereo geometry important in computer vision?,"Stereo geometry is important in computer vision because it allows for depth perception by identifying common points in two camera views, which is essential for tasks like 3D reconstruction and autonomous navigation."
B21_ComputerVision,Computer Vision,What is the significance of the Viola/Jones face detector in computer vision?,"The Viola/Jones face detector is significant because it introduced a real-time object detection approach using Haar features and an attentional cascade, which was a breakthrough in fast and efficient face detection."
B21_ComputerVision,Computer Vision,What are some modern approaches to object detection mentioned in the document?,"Some modern approaches to object detection mentioned include YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector), and RetinaNet, which balance speed and accuracy in detecting objects."
B21_ComputerVision,Computer Vision,What are some key challenges in image segmentation in computer vision?,"Key challenges in image segmentation include the need to balance classification and localization, as segmentation requires both a broad context for accurate classification and sensitivity to location for precise boundary detection."
Transfer_Learning_V1.10,Transfer Learning,What is transfer learning?,"Transfer learning involves taking the knowledge gained from a pre-trained model on one task and applying it to a different, but related task. This approach allows for leveraging pre-existing patterns learned by the model, making it easier and faster to train on new tasks with less data."
Transfer_Learning_V1.10,Transfer Learning,Why is transfer learning beneficial?,"Transfer learning is beneficial because it addresses the challenges of limited data availability, long training times for deep learning models, and the need for extensive computational resources. By using a pre-trained model, it is possible to achieve good performance even on small datasets with less computational cost."
Transfer_Learning_V1.10,Transfer Learning,What are the two main components of a Convolutional Neural Network (CNN) in the context of transfer learning?,"The two main components of a CNN in transfer learning are the convolutional base, which is responsible for feature extraction, and the densely connected classifier, which is typically retrained or fine-tuned for the specific task at hand."
Transfer_Learning_V1.10,Transfer Learning,What are the steps involved in using a pre-trained model for transfer learning?,"The steps involved in using a pre-trained model include:	
1	Start with a pre-trained network.
2	Partition the network into featurizers and classifiers.
3	Re-train the classifier layers with new data.
4	Unfreeze the weights of the later layers and fine-tune the network as needed."
Transfer_Learning_V1.10,Transfer Learning,How do you decide which layers to re-train during transfer learning?,"The decision on which layers to re-train depends on the domain and dataset similarity. If the new task is very different from the original task, you might retrain more layers starting from the last fully connected and convolutional layers. If the tasks are similar, only the last layers may need retraining."
Transfer_Learning_V1.10,Transfer Learning,What are some popular pre-trained models mentioned in the document?,"Some popular pre-trained models mentioned are AlexNet (2012), VGGNet (2014), Inception (2014), and ResNet-152 (2015). These models have been trained on large datasets and are widely used for transfer learning in various applications."
Transfer_Learning_V1.10,Transfer Learning,What is the main idea behind feature extraction in transfer learning?,"The main idea behind feature extraction is to reuse the features learned by the convolutional base of a pre-trained model for a new task. Only the classifier is retrained or fine-tuned, which makes the training process faster and less data-intensive."
Transfer_Learning_V1.10,Transfer Learning,How does the concept of dataset size and similarity affect the transfer learning strategy?,"The transfer learning strategy varies with dataset size and similarity:	
	Large and similar dataset: Retain the architecture and initial weights, only customize the last layer for the number of classes.
	Large and different dataset: Train the model from scratch.
	Small and similar dataset: Don’t fine-tune to avoid overfitting.
	Small and different dataset: Customize earlier layers and train the classifier."
Transfer_Learning_V1.10,Transfer Learning,"What is data augmentation, and why is it used in transfer learning?","Data augmentation is a technique used to artificially increase the size of the training dataset by applying various transformations such as flipping, rotating, or zooming in/out on the images. It is used to improve model performance and reduce overfitting, especially when dealing with small datasets."
Transfer_Learning_V1.10,Transfer Learning,What are some challenges in using transfer learning with small datasets?,"Challenges include the risk of overfitting due to the limited amount of data, and high variance in model performance estimation. Data augmentation and careful fine-tuning are strategies used to mitigate these challenges."
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What is the primary difference between recognition and verification in the context of Siamese networks?,"Recognition involves identifying which of the K classes a sample belongs to, while verification is about determining if a given sample belongs to a specific class, often by comparing it with known samples (e.g., biometric verification). "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,How does a Siamese network typically handle training and verification?,"During verification, Siamese networks often use nearest neighbors to find distances to the samples from the class under question and apply a subject-specific variable threshold. For training, the network uses a small number of samples, often employing one-shot learning to find a feature space suitable for the local geometry. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What is the objective of the contrastive loss function in Siamese networks? ,"The contrastive loss function aims to minimize the distance between similar pairs and maximize the distance between dissimilar pairs. It is defined as 1?Y12DW2+Y12max?(0,m?DW2)1 - Y \frac{1}{2} D_W^2 + Y \frac{1}{2} \max(0, m - D_W^2)1?Y21 DW2 +Y21 max(0,m?DW2 ), where YYY is 0 for similar and 1 for dissimilar pairs. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,"What is a triplet loss function, and what does it aim to achieve? ",The triplet loss function is used to ensure that the distance between an anchor and a positive sample (same class) is less than the distance between the anchor and a negative sample (different class) by at least a margin. It helps in expanding inter-class distance while shrinking intra-class distance. 
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What are the three different scenarios in the context of a triplet loss function? ,"The three scenarios are: 
Easy: The distance to the positive sample is naturally less than to the negative sample. 
Hard: The distance to the positive sample is greater than to the negative sample. 
Semi-hard: The distance to the positive sample is less than to the negative sample, but the difference is less than the margin. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What is the main challenge of using traditional triplet loss in deep learning?," Traditional triplet loss can suffer from slow convergence and instability, especially with a huge amount of training data, making it difficult to achieve optimal performance quickly. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What are the two main components of the Center Loss function?,"The Center Loss function comprises two terms: one for inter-class separability (softmax) and another for intra-class compactness, with a balancing factor ?\lambda? that adjusts the influence of each term. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,"What is the Orthogonality Loss, and why was it proposed?", Orthogonality Loss was proposed to enhance the recognition ability of deep face features by punishing the mean value and second moment of the weight matrix of generated feature vectors. It addresses the limitation of traditional softmax loss in distinguishing between classes in high-dimensional feature spaces. 
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,How does the Siamese network apply in the context of person identification?," In person identification, Siamese networks are used to match across different views, often focusing on face recognition tasks. They are trained to reduce the distance between embeddings of the same person while increasing the distance between embeddings of different people. "
L3-MoreArchitectures_V1.8-Loss_Functions,More Architectures & Loss Functions,What is a practical application of Siamese networks in natural language processing (NLP)?,"Siamese networks are used in NLP for tasks like sentence completion, response matching, and paraphrase identification, where they compare the embeddings of sentences to determine similarity or match. "
Model_Compression_V1.8__1_,Model Compression,What is the purpose of pruning in neural networks? ,"Pruning aims to compress neural networks by removing redundant parameters, which have negligible value and can be ignored without affecting the model's performance. This reduces the model's size and computational complexity."
Model_Compression_V1.8__1_,Model Compression,What are the types of pruning mentioned in the document?,"The document discusses four types of pruning: Fine Pruning (pruning individual weights), Coarse Pruning (pruning neurons and layers), Static Pruning (pruning after training), and Dynamic Pruning (pruning during training)."
Model_Compression_V1.8__1_,Model Compression,How does weight pruning benefit model performance?,"Weight pruning makes matrices sparse, which can be stored more efficiently and allows for faster sparse matrix multiplications. This reduces the model's size and computation requirements, making it more efficient during inference."
Model_Compression_V1.8__1_,Model Compression,What is the role of L1 regularization in ensuring sparsity during training?,"L1 regularization encourages sparsity by adding a penalty proportional to the absolute value of the weights to the loss function. This drives many weights to zero, making the model more efficient without significantly impacting performance."
Model_Compression_V1.8__1_,Model Compression,"What is binary quantization, and what are its trade-offs?","Binary quantization reduces model size by 32 times and significantly speeds up matrix multiplications. However, it comes with a trade-off in accuracy, leading to about a 20% drop in top-5 classification accuracy on the ILSVRC dataset."
Model_Compression_V1.8__1_,Model Compression,What is the process of non-uniform quantization or weight sharing?,"Non-uniform quantization involves performing k-means clustering on weights, allowing weights to be shared among clusters. This method significantly reduces storage requirements by encoding weights with fewer bits."
Model_Compression_V1.8__1_,Model Compression,How does neuron pruning differ from weight pruning?,"Neuron pruning involves removing entire rows and columns in a weight matrix, which directly reduces the number of neurons in the network. This results in faster matrix multiplications and improved test-time performance."
Model_Compression_V1.8__1_,Model Compression,What is the concept behind student-teacher networks in model compression?,"Student-teacher networks involve training a smaller, shallower network (the student) using the output of a larger, more complex network (the teacher) as the target. This approach helps the student network learn more effectively and efficiently."
Model_Compression_V1.8__1_,Model Compression,What is the effect of using a regularizer during neuron pruning?,"Regularizers during neuron pruning force the input and output connections of neurons to be small, leading to the removal of weak connections. Neurons with no significant connections are discarded, simplifying the network's structure."
Model_Compression_V1.8__1_,Model Compression,What are the benefits of model compression techniques like pruning and quantization?,"Model compression techniques reduce the size and computational complexity of neural networks, making them more suitable for deployment on resource-constrained devices like mobile phones. These techniques also improve energy efficiency and reduce latency during inference."
L1-GAN_V1.8,GAN,What is the primary difference between supervised and unsupervised learning?,"Supervised learning involves data with labels, where the goal is to learn a function that maps inputs to outputs (e.g., classification, regression). Unsupervised learning involves data without labels, aiming to learn the underlying hidden structure of the data (e.g., clustering, dimensionality reduction)."
L1-GAN_V1.8,GAN,What is the goal of generative modeling?,The goal of generative modeling is to generate new samples that come from the same distribution as the training data.
L1-GAN_V1.8,GAN,What is the typical architecture of a Generative Adversarial Network (GAN)?,"A GAN consists of two neural networks: the generator (G), which tries to produce data that is indistinguishable from real data, and the discriminator (D), which tries to differentiate between real and generated data. The two networks are trained simultaneously in a game-theoretic framework."
L1-GAN_V1.8,GAN,How can autoencoders be used in supervised learning tasks?,"After training, the decoder of an autoencoder can be discarded, and the compressed code generated by the encoder can be used for supervised learning tasks, particularly when dealing with small training datasets."
L1-GAN_V1.8,GAN,What is the main function of the discriminator in a GAN?,The discriminator's main function is to distinguish between real samples from the data distribution and fake samples generated by the generator.
L1-GAN_V1.8,GAN,What is one of the major limitations of GANs?,"One major limitation of GANs is the difficulty in evaluating the quality of generated outputs, as well as the potential ethical concerns related to generating realistic fake data."
L1-GAN_V1.8,GAN,What are some examples of applications for GANs mentioned in the document?,"GANs are used for applications like image-to-image translation, synthetic data generation, and style-based generation, where separate high-level and fine-level attributes (e.g., pose, identity, freckles, hair texture) can be controlled."
L1-GAN_V1.8,GAN,What is a Conditional GAN?,A Conditional GAN is a type of GAN where both the generator and the discriminator have access to additional information (such as class labels or data from another modality) to guide the generation process.
L1-GAN_V1.8,GAN,How does the Progressive GAN improve upon traditional GANs?,"The Progressive GAN improves upon traditional GANs by progressively increasing the resolution of generated images during training, leading to more stable training and higher quality images."
L1-GAN_V1.8,GAN,What is one emerging concern with generative models like GANs?,"An emerging concern with generative models is the potential for them to be used to create realistic but fake data, raising ethical concerns about the misuse of such technology."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What is the first step in the Machine Learning process as described in the document?,The first step is to convert a real-world problem into a prediction task.
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What are some examples of features that might be used in a binary classifier for job selection?,"Examples of features include years of job experience, previous companies, and keywords in the resume."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What are some types of models mentioned for training in the ML process?,"The models mentioned include Decision Trees, SVM (Support Vector Machines), Random Forest, Neural Networks, and Logistic Regression."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What are the different types of metrics mentioned for evaluating a machine learning model?,"The metrics include Precision, Recall, AUC (Area Under the Curve), Accuracy, and F1 Score."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What does the Big Data Analytics process start with?,"It starts with understanding the business problem, the current solution, and the Return on Investment (ROI)."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What should you consider when engineering features for a model?,"You should consider transforming data, using PCA (Principal Component Analysis), creating smaller categories for categorical data, deriving additional attributes, and experimenting with hyperparameters."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What is important when designing a validation strategy for a model?,"It is important to divide the data into training, test, and cross-validation (CV) sets and plot error metrics for all models on all data to pick the best one."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What qualities should you consider when evaluating a classifier?,"Consider classification philosophy, train time, test time, accuracy, interpretability, classification decision boundary, and RAM usage at test time."
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What is a key aspect of analyzing data in the Big Data Analytics process?,A key aspect is to define the target for supervised learning and derive relevant attributes through brainstorming hierarchically.
Deployment_of_ML_Solutions_V1.8.pptx,Deployment of ML Solutions,What is a critical consideration mentioned when building a machine learning model?,A critical consideration is to build the most efficient and accurate model possible by regularizing and experimenting with various hyperparameters.
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What is the primary context in which the attention mechanism is explained in the document?,The attention mechanism is explained in the context of language translation using the seq2seq (encoder-decoder) architecture.
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What is the function of the encoder in the seq2seq model?,"The encoder ingests the input sequence and computes a final hidden state vector, h(T), which serves as a compressed representation of the entire input sequence."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What problem does the document highlight with the basic seq2seq model when dealing with long input sequences?,"The problem is that the final encoder state h(T) has a fixed size and must represent the entire input sequence, which can be challenging for very long sentences."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,How does the decoder in the seq2seq model begin generating an output sequence?,The decoder begins with a special '<SOS>' token indicating the start of the sequence and uses the final hidden state from the encoder to start generating the output sequence one word at a time.
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What does the attention mechanism aim to solve in the seq2seq model?,The attention mechanism aims to solve the issue of the decoder focusing only on the final hidden state by allowing it to pay attention to different parts of the input sequence at each time step.
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,How does the attention mechanism improve the encoder-decoder architecture?,"Instead of feeding only the last hidden state of the encoder to the decoder, the attention mechanism feeds all hidden states into the decoder at each time step, with certain weightages (alpha) assigned to them."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What is a context vector in the context of the attention mechanism?,"A context vector is a weighted sum of all hidden states from the encoder, where the weights are determined by the attention mechanism."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What is the role of the alignment score in calculating attention weights?,"The alignment score, denoted as ei,je_{i,j}ei,j?, determines how important the jth word in the input sequence is for producing the ith word in the output sequence, based on the decoder's current state and the input word."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,"How is the attention weight ?i,j\alpha_{i,j}?i,j? calculated from the alignment score?","The attention weight ?i,j\alpha_{i,j}?i,j? is calculated by applying a SoftMax function to the alignment score, ensuring that the weights sum to one, similar to a probability distribution."
Birth_of_Attention_mechanism.docx,Birth of Attention mechanism.docx,What is the final purpose of the attention weights in the attention mechanism?,The attention weights determine how much focus the decoder should place on each input word when generating each output word in the sequence.
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What is an API?,"An API (Application Programming Interface) is a set of functions and procedures that allows the creation of applications that access the features or data of an operating system, application, or other service."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What distinguishes Cognitive APIs from regular APIs?,"Cognitive APIs are specialized APIs that provide cognitive (data science) services, such as machine learning, natural language processing, and computer vision, often offered by cloud providers like Microsoft, Amazon, Google, IBM, and Twitter."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What are some key features of APIs?,"Key features of APIs include input/output mechanisms, rate limits, and authentication methods such as HTTP auth, API keys, and OAuth."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What is the role of an API key in API usage?,"An API key is a unique generated value assigned to each first-time user, signifying that the user is known and allowing them to access the API's services."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What are Vision APIs and give an example of one?,"Vision APIs are a type of Cognitive API focused on processing and analyzing visual data. An example is the Azure Computer Vision API, which can perform tasks like face detection and image recognition."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,How does Azure's Face API handle face detection?,"Azure's Face API detects faces in images and returns data such as face attributes (age, gender, emotion), face landmarks (pupil positions, nose tip), and other characteristics like occlusion, exposure, and noise levels."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What is the purpose of the Immersive Reader API?,"The Immersive Reader API is designed to improve reading comprehension by providing features such as text decoding, highlighting, and voice narration, helping users with reading difficulties or those learning a new language."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,How can Google Vision API be set up for use?,"To set up Google Vision API, you need to create a GCP project, enable billing, enable the API, create a service account key, set the environment variable for the application credentials, install the client library, and run the appropriate code."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What is a use case for the Text Analytics API on Azure?,"A use case for the Text Analytics API on Azure includes extracting key phrases, sentiment analysis, language detection, and named entity recognition from a block of text, useful in applications like customer feedback analysis."
Cognitive_APIs_Cloud_API.pptx,Cognitive APIs & Cloud API,What type of data can the Google Translate API handle?,"The Google Translate API can translate text data between different languages, allowing developers to incorporate language translation capabilities into their applications."
